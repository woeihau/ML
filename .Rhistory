class(mtcars[0])
summary(mtcars)
plot(mpg~.,data=mtcars)
?mtcars
mtcars
mtcars$vs <- as.factor(mtcars$vs)
plot(mpg~vs,data=mtcars)
plot(mpg~cyl,mtcars)
plot(mpg~am,mtcars)
?plot
ggplot(data=mtcars, x=am, y=mpg)
ggplot(data=mtcars, x=am, y=mpg) + geom_boxplot()
ggplot(data=mtcars, aes(am, mpg)) + geom_boxplot()
ggplot(data=mtcars, aes(am, mpg)) + geom_boxplot() + geom_jitter()
ggplot(data=mtcars, aes(am, mpg, fill=am)) + geom_boxplot() + geom_jitter()
ggplot(data=mtcars, aes(am, mpg, fill=am)) + geom_boxplot() + geom_jitter() + labs(title="MPG vs Transmission Type", x="Transmission Type", y="Miles per Gallon (MPG)")
res <- t.test(mtcars$mpg ~ mtcars$am)
summary(res)
res
fit <- lm(mpg ~ am, data=mtcars)
summary(fit)
fitAll <- lm(mpg~., data=mtcars)
summary(fitAll)
?step
fitAIC <- step(fitAll,direction = "forward")
fitAIC_FW <- step(fitAll,direction = "forward")
fitAIC_BW <- step(fitAll,direction = "backward")
summary(fitAIC_BW)
summary(fitAIC_FW)
fitAIC <- step(fitAll,direction = "both")
summary(fitAIC)
anova(fit, fitAll, fitAIC)
confint(fitAIC)
confint(fitAll)
confint(fit)
plot(fitAIC)
anova(fit,fitAll,fitAIC)
anova(fit,fitAll,fitAIC, test="Chi")
anova(fit,fitAll,fitAIC)
anova(fit,fitAIC)
par(mfrow = c(2,2))
plot(fitAIC)
summary(fitAIC)
install.packages("unquote")
library(mass)
install.packages("MASS")
library(mass)
?shuttle
library(MASS)
?shuttle
fit <- lm(use ~ wind, shuttle)
summary(shuttle)
data <- shuttle
data$use <- relevel(c("auto","noauto"),c(1,0))
data$use2 <- as.numeric(data$use=="auto")
data$use2
data
fit <- glm(use2 ~ factor(wind)-1, data = data)
summary(fit)
exp(coef(fit))
fit <- glm(use2 ~ factor(wind)-1, family="binomial" data = data)
fit <- glm(use2 ~ factor(wind)-1, family="binomial", data = data)
summary(fit)$coef
odds <- exp(cbind(OddRatio = coef(fit), confint(fit)))
odds
odds[1] - odds[2]
rm(data)
dt <- shuttle
dt
head(dt)
shuttle$use <- factor(shuttle$use, levels = c("auto", "noauto"), labels = c(1,0))
head(dt)
dt$use <- factor(dt$use, levels = c("auto", "noauto"), labels = c(1,0))
head(dt)
rm(fit)
rm(fitAIC)
rm(fitAIC_BW)
rm(fitAIC_FW)
rm(fitAll)
fit1 <- glm(use ~ wind - 1, data=shuttle, family="binomial")
summary(fit1)
summary(fit1)$coef
summary(fit1)$coef[1]
summary(fit1)$coef[2]
windhead <- fit1$coef[1]
windtail <- fit1$coef[2]
exp(windtail)/exp(windhead)
fit2 <- glm(use ~ wind + magn - 1, data=shuttle, family="binomial")
summary(fit2)
winhead2 <- fit2$coef[1]
wintail2 <- fit2$coef[2]
exp(wintail2)/exp(winhead2)
data("InsectSprays")
InsectSprays
head(InsectSprays)
data("InsectSprays")
fit <- glm(count ~ spray - 1, family="poisson", data=InsectSprays)
exp(fit$coef[1])/exp(fit$coef[2])
fit <- glm(count ~ spray - 1, family="poisson", data=InsectSprays)
summary(fit)
fit <- glm(count ~ spray - 1 + offset(1), family="poisson", data=InsectSprays)
fit <- glm(count ~ spray - 1 + offset(10), family="poisson", data=InsectSprays)
fit <- glm(count ~ spray - 1 + offset(spray), family="poisson", data=InsectSprays)
fit <- glm(count ~ spray - 1 + offset(count), family="poisson", data=InsectSprays)
summary(fit)
fit2 <- glm(count ~ spray - 1 + offset(log(10) + count), family="poisson", data=InsectSprays)
summary(fit2)
x <- -5:5
y < c(5.12, 3.93, 2.67, 1.87, 00.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
y <- c(5.12, 3.93, 2.67, 1.87, 00.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
splineTerms <- sapply(knots, function(knot) (x>knot)*(x-knot))
knots <- c(0)
splineTerms <- sapply(knots, function(knot) (x>knot)*(x-knot))
xmat<- cbind(1,x,splineTerms)
fit<-lm(1,x,splineTerms)
fit<-lm(y~xmat-1)
yhat<-predict(fit)
summary(yhat)
summary(fit)
yhat
(yhat[10]-yhat[6])/4
exit
bye
exit
cls
clear
library(swirl)
swirl()
library(kernlab)
data(spam)
head(spam)
library(dpylr)
library(dplyr)
spamFilter <- select(spam, type, your)
spamFilter
summary(spamFilter)
summary(spamFilter$summary)
str(spamFilter)
str(spam)
summary(spam)
library(caret)
inTrain <- createDataPartition(y=spam$type,p=0.75,list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
dim(training)
set.seed(32343)
modelFit <- train(type ~., data=training, method="glm")
modelFit
modelFit$finalModel
predictions <- predict(modelFit,newdata=testing)
predictions
summary(predictions)
confusionMatrix(predictions,testing$type)
set.seed(32323)
folds <- createFolds(y=spam$type, k=10, list=TRUE, returnTrain=TRUE)
sapply(folds, length)
folds
folds[[1]][1:10]
library(ISLR)
install.packages("ISLR")
library(ISLR)
librar(ggplot2)
data(Wage)
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training)
dim(testing)
featuresPlot(x=training)
featuresPlot(x=training[,c("age","education","jobclass")],y=training$wage,plot="pairs")
featurePlot(x=training[,c("age","education","jobclass")],y=training$wage,plot="pairs")
plot(.,training$wage)
plot(training,training$wage)
qplot(age,wage,colour=jobclass,data=training)
qplot(age,wage,data=training)
qplot(age,wage,colour=jobclass,data=training)
summary(Wage)
qplot(age,wage,colour=health,data=training)
qplot(age,wage,colour=jobclass,data=training)
qplot(age,wage,colour=education,data=training)
qq <- qplot(age,wage,colour=education,data=training)
qq + geom_smooth(method="lm",formula=y~x)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
cutWage <- cut2(training$wage,g=3)
table(cutWage)
p1 <- qplot(cutWage,age,data=training,fill=cutWage,geom=c("boxplot"))
p1
p1 <- qplot(cutWage,age,data=training,fill=cutWage,geom=c("boxplot","jitter"))
p1
p2 <- qplot(cutWage,age,data=training,fill=cutWage,geom=c("boxplot","jitter"))
p1 <- qplot(cutWage,age,data=training,fill=cutWage,geom=c("boxplot"))
grid.arrange(p1,p2,ncol=2)
table(training$jobclass)
dummies <- dummyVars(wage ~ jobclass, data=training)
head(predict(dummies,newdata=training))
dummies
str(dummies)
summary(dummies)
nsv <- nearZeroVar(training,saveMetrics=TRUE)
nsv
data(iris)
names(iris)
table(iris$Species)
inTarin <- createDataPartition(y=iris$Species,p=0.7,list=FALSE)
training<-iris[inTrain,]
testing<-iris[-inTrain,]
dim(training)
dim(testing)
inTrain <- createDataPartition(y=iris$Species,p=0.7,list=FALSE)
training<-iris[inTrain,]
testing<-iris[-inTrain,]
dim(training)
dim(testing)
modFit <- train(Species ~., method="rpart",data=training)
library(rpart)
modFit <- train(Species ~., method="rpart",data=training)
modFit$finalModel
plot(modFit$finalModel,uniform=TRUE,main="Classification Tree")
library(rattle)
install.packages("rattle")
library(rattle)
cls
learlist
library(AppliedPredictiveModeling)
data("segmentationOriginal")
library(caret)
set.seed(125)
summary(segmentationOriginal)
summary(segmentationOriginal$Case)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.7,list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
summary(training)
dim(training)
dim(testing)
summary(segmentationOriginal$Class)
inTrain <- segmentationOriginal$Case =="Train"
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training)
dim(testing)
summary(segmentationOriginal$Case)
testing <- segmentationOriginal[!inTrain,]
dim(testing)
cartModel <- train(Class ~ ., data=training,method="rpart")
cartModel$finalModel
cartModel$finalModel
plot(cartModel$finalModel,uniform=TRUE)
text(cartModel$finalModel,cex=0.8)
library(pgmm)
install.packages("pgmm")
newdata = as.data.frame(t(colMeans(olive)))
library(olive)
install.packages("olive")
library(olive)
library(pgmm)
data(olive)
newdata = as.data.frame(t(colMeans(olive)))
summary(olive)
summary(olive$Area)
olive[,-1]
head(olive[,-1])
modelFit <- train(Area~.,data=olive,method="rpart2")
modelFit$finalModel
predict(modelFit,newdata)
summary(modelFit)
dim(olive)
summary(olive$Area)
newdata
modelFit <- train(Area~.,data=olive,method="class")
modelFit <- train(Area~.,data=olive,method="rpart")
predict(modelFit,newdata)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data("SAheart")
set.seed(8484)
train=sample(1:dim(SAheart),size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
str(SAheart)
summary(SAheart)
modelFit <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,method="glm",family="binomial",data=SAheart)
missClass = function(values,prediction){sum(((prediction >0.5)*1) != values)/length(values)}
missclass(trainSA$chd,predict(model,newdata=trainSA))
missClass(trainSA$chd,predict(model,newdata=trainSA))
missClass(trainSA$chd,predict(modelFit,newdata=trainSA))
missClass(testSA$chd,predict(modelFit,newdata=testSA))
predictTrain <- predict(modelFit,trainSA)
predictTest <- predict(modelFit,testSA)
missClass(trainSA$chd,predictTrain)
modelFit <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,method="glm",family="binomial",data=trainSA)
predictTrain <- predict(modelFit,trainSA)
predictTest <- predict(modelFit,testSA)
missClass(trainSA$chd,predictTrain)
missClass(testSA$chd,predictTest)
predictTrain$finalModel
summary(predictTrain)
predictTrain
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
dim(vowel.train)
dim(vowel.test)
summary(vowel.train$y)
summary(vowel.test$y)
library(randomForest)
install.packages("randomForest")
library(randomForest)
fit <- randomForest(y~.,data=vowel.train)
order(varImp(fit),decreasing=T)
fit <- randomForest(y~.,data=vowel.train,importance=FALSE)
order(varImp(fit),decreasing=T)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modelRf)
fancyRpartPlot(trainSA)
fancyRpartPlot(predictTrain)
?fancyRpartPlot
## Use rpart to build a decision tree.
library(rpart)
## Set up the data for modelling.
set.seed(42)
ds     <- weather
target <- "RainTomorrow"
risk   <- "RISK_MM"
ignore <- c("Date", "Location", risk)
vars   <- setdiff(names(ds), ignore)
nobs   <- nrow(ds)
form   <- formula(paste(target, "~ ."))
train  <- sample(nobs, 0.7*nobs)
test   <- setdiff(seq_len(nobs), train)
actual <- ds[test, target]
risks  <- ds[test, risk]
# Build the model.
model <- rpart(form, data=ds[train, vars])
## Plot the model.
fancyRpartPlot(model)
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
## Use rpart to build a decision tree.
library(rpart)
## Set up the data for modelling.
set.seed(42)
ds     <- weather
target <- "RainTomorrow"
risk   <- "RISK_MM"
ignore <- c("Date", "Location", risk)
vars   <- setdiff(names(ds), ignore)
nobs   <- nrow(ds)
form   <- formula(paste(target, "~ ."))
train  <- sample(nobs, 0.7*nobs)
test   <- setdiff(seq_len(nobs), train)
actual <- ds[test, target]
risks  <- ds[test, risk]
# Build the model.
model <- rpart(form, data=ds[train, vars])
## Plot the model.
fancyRpartPlot(model)
install.packages("rpart")
library(rattle)
## Use rpart to build a decision tree.
library(rpart)
## Set up the data for modelling.
set.seed(42)
ds     <- weather
target <- "RainTomorrow"
risk   <- "RISK_MM"
ignore <- c("Date", "Location", risk)
vars   <- setdiff(names(ds), ignore)
nobs   <- nrow(ds)
form   <- formula(paste(target, "~ ."))
train  <- sample(nobs, 0.7*nobs)
test   <- setdiff(seq_len(nobs), train)
actual <- ds[test, target]
risks  <- ds[test, risk]
# Build the model.
model <- rpart(form, data=ds[train, vars])
## Plot the model.
fancyRpartPlot(model)
setwd("D:\Dropbox\Coursera/ML/")
setwd("D:\Dropbox\Coursera\ML\")
setwd("D:/Dropbox/Coursera/ML/")
getwd()
list.files()
trainCSV <- read.csv("pml-training.csv")
head(trainCSV)
dim(trainCSV)
str(trainCSV)
summary(trainCSV$classe)
summary(trainCSV)
?read.csv
trainCSV2 <- complete.cases(trainCSV)
summary(trainCSV2)
trainCSV[,colSums(is.na(trainCSV))==0]
dat <- trainCSV[,colSums(is.na(trainCSV))==0]
dim(dat)
dim(trainCSV)
dim(trainCSV2)
str(trainCSV2)
trainCSV2 <- trainCSV[,complete.cases(trainCSV)]
trainCSV2 <- trainCSV[,complete.cases(trainCSV)==TRUE]
complete.cases(trainCSV)
dim(trainCSV2)
summary(trainCSV2)
?read.csv
str(trainCSV)
summary(trainCSV)
trainCSV2 <- trainCSV[complete.cases(trainCSV),]
ttrainCSV
trainCSV2
summary(trainCSV2$classe)
?complete.cases
summary(trainCSV)
sapply(names(trainCSV),is.numeric(trainCSV))
trainCSV2 <- trainCSV[,sapply(trainCSV,is.numeric)]
dim(trainCSV2)
dim(trainCSV)
trainCSV2 <- trainCSV[,sapply(trainCSV,is.numeric) || c("classe")]
trainCSV2 <- trainCSV[,sapply(trainCSV,is.numeric) || c("classe")]
summary(trainCSV2)
trainCSV3 <- trainCSV[,sapply(trainCSV,is.numeric)]
summary(trainCSV3)
str(trainCSV)
trainCSV2 <- trainCSV[,colSums(is.na(trainCSV))==0]
fields <- grepl("dumbbell|arm|belt|classe")
fields <- grepl("dumbbell|arm|belt|classe",names(trainCSV2))
fields
trainCSV3 <- trainCSV2[,fields]
testCSV2 <- testCSV[,colSums(is.na(testCSV))==0]
testCSV <- read.csv("pml-testing.csv")
testCSV2 <- testCSV[,colSums(is.na(testCSV))==0]
testCSV3 <- testCSV2[,fields]
fields_train <- grepl("dumbbell|arm|belt|classe",names(trainCSV2))
fields_test <- grepl("dumbbell|arm|belt|classe",names(testCSV2))
testCSV3 <- testCSV2[,fields_test]
summary(trainCSV3)
str(trainCSV3)
summary(trainCSV3$kurtosis_roll_forearm)
fields_train <- grepl(is.numeric(,names(trainCSV2))
)
fields_train <- grepl(is.numeric(),names(trainCSV2)
)
fields_train <- grepl(is.numeric,names(trainCSV2))
testCSV2 <- testCSV[,colSums(is.na(trainCSV))==0]
fields <- grepl("dumbbell|arm|belt|classe",names(trainCSV2))
trainCSV3 <- trainCSV2[,fields]
testCSV3 <- testCSV2[,fields]
#Read the data from CSV files.
trainCSV <- read.csv("pml-training.csv")
testCSV <- read.csv("pml-testing.csv")
# Remove those columns with NA values
trainCSV2 <- trainCSV[,colSums(is.na(trainCSV))==0]
testCSV2 <- testCSV[,colSums(is.na(trainCSV))==0]
# Keep only certain columns
fields <- grepl("dumbbell|arm|belt|classe",names(trainCSV2))
trainCSV3 <- trainCSV2[,fields]
testCSV3 <- testCSV2[,fields]
classe <- trainCSV$classe
trainCSV4 <- trainCSV3[,sapply(trainCSV3,is.numeric)]
testCSV4 <- testCSV3[,sapply(testCSV3,is.numeric)]
trainCSV4 <- trainCSV3[,sapply(trainCSV3,is.numeric)]
testCSV4 <- testCSV3[,sapply(testCSV3,is.numeric)]
trainCSV4 <- trainCSV3[,sapply(trainCSV3,is.numeric)]
testCSV4 <- testCSV3[,sapply(trainCSV3,is.numeric)]
trainCSV3 <- trainCSV2[,fields]
testCSV3 <- testCSV2[,fields]
rm(trainCSV4)
rm(testCSV4)
trainCSV4 <- trainCSV3[,sapply(trainCSV3,is.numeric)]
testCSV4 <- testCSV3[,sapply(testCSV3,is.numeric)]
Compare(trainCSV4,testCSV4)
str(trainCSV4)
dat <- c(names(trainCSV4),names(testCSV4))
dat
summary(dat)
order(dat)
summary(testCSV3$problem_id)
training <- trainCSV4
training$classe <- classe
testing <- testCSV4
library(caret)
library(knitr)
library(ggplot2)
library(dplyr)
library(randomForest)
library(rattle)
set.seed(12345)
inTrain <- createDataPartition(training$classe,p=0.6, list=FALSE)
trainData <- training[inTrain,]
testData <- training[-inTrain,]
?randomForest
modelRF <- randomForest(classe~., data=trainData)
modelRF
summary(modelRF)
modelRF
predictionRF <- predict(modelRF,testData)
predictionRF
confusionMatrix(testData$classe,predictionRF)
